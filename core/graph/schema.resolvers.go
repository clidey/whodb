/*
 * Copyright 2026 Clidey, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package graph

// This file will be automatically regenerated based on the schema, any resolver
// implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.84

import (
	"context"
	"errors"
	"fmt"
	"strings"
	"time"

	"github.com/clidey/whodb/core/graph/model"
	"github.com/clidey/whodb/core/src"
	"github.com/clidey/whodb/core/src/analytics"
	"github.com/clidey/whodb/core/src/auth"
	"github.com/clidey/whodb/core/src/aws"
	"github.com/clidey/whodb/core/src/common"
	"github.com/clidey/whodb/core/src/engine"
	"github.com/clidey/whodb/core/src/env"
	"github.com/clidey/whodb/core/src/llm"
	"github.com/clidey/whodb/core/src/log"
	"github.com/clidey/whodb/core/src/plugins/ssl"
	"github.com/clidey/whodb/core/src/providers"
	"github.com/clidey/whodb/core/src/settings"
	"golang.org/x/sync/errgroup"
)

// Login is the resolver for the Login field.
func (r *mutationResolver) Login(ctx context.Context, credentials model.LoginCredentials) (*model.StatusResponse, error) {
	if env.DisableCredentialForm {
		log.LogFields(log.Fields{
			"type":     credentials.Type,
			"hostname": credentials.Hostname,
			"username": credentials.Username,
			"database": credentials.Database,
		}).Error("Login with credentials is disabled; use preconfigured connections")
		return nil, errors.New("login with credentials is disabled; use preconfigured connections")
	}

	advanced := make([]engine.Record, 0, len(credentials.Advanced))
	for _, recordInput := range credentials.Advanced {
		advanced = append(advanced, engine.Record{
			Key:   recordInput.Key,
			Value: recordInput.Value,
		})
	}

	hasProfileID := credentials.ID != nil && strings.TrimSpace(*credentials.ID) != ""
	identity := strings.TrimSpace(analytics.MetadataFromContext(ctx).DistinctID)
	hasIdentity := identity != "" && identity != "disabled"

	if hasIdentity {
		analytics.CaptureWithDistinctID(ctx, identity, "login.attempt", map[string]any{
			"database_type":      credentials.Type,
			"profile_id_present": hasProfileID,
		})
	}

	if !src.MainEngine.Choose(engine.DatabaseType(credentials.Type)).IsAvailable(&engine.PluginConfig{
		Credentials: &engine.Credentials{
			Type:     credentials.Type,
			Hostname: credentials.Hostname,
			Username: credentials.Username,
			Password: credentials.Password,
			Database: credentials.Database,
			Advanced: advanced,
		},
	}) {
		log.LogFields(log.Fields{
			"type":     credentials.Type,
			"hostname": credentials.Hostname,
			"username": credentials.Username,
			"database": credentials.Database,
		}).Error("Database connection failed during login - credentials unauthorized")

		if hasIdentity {
			analytics.CaptureWithDistinctID(ctx, identity, "login.denied", map[string]any{
				"database_type":      credentials.Type,
				"profile_id_present": hasProfileID,
			})
		}
		return nil, errors.New("unauthorized")
	}

	resp, err := auth.Login(ctx, &credentials)
	if err != nil {
		if hasIdentity {
			analytics.CaptureError(ctx, "login.execute", err, map[string]any{
				"database_type":      credentials.Type,
				"profile_id_present": hasProfileID,
			})
		}
		return nil, err
	}

	if hasIdentity {
		traits := map[string]any{
			"profile_id_present": hasProfileID,
		}
		if hashedHost := analytics.HashIdentifier(credentials.Hostname); hashedHost != "" {
			traits["hostname_hash"] = hashedHost
		}
		if hashedDatabase := analytics.HashIdentifier(credentials.Database); hashedDatabase != "" {
			traits["database_hash"] = hashedDatabase
		}

		analytics.IdentifyWithDistinctID(ctx, identity, traits)
		analytics.CaptureWithDistinctID(ctx, identity, "login.success", map[string]any{
			"database_type":      credentials.Type,
			"profile_id_present": hasProfileID,
		})
	}

	return resp, nil
}

// LoginWithProfile is the resolver for the LoginWithProfile field.
func (r *mutationResolver) LoginWithProfile(ctx context.Context, profile model.LoginProfileInput) (*model.StatusResponse, error) {
	profiles := src.GetLoginProfiles()
	for i, loginProfile := range profiles {
		profileId := src.GetLoginProfileId(i, loginProfile)
		if profile.ID == profileId {

			resolved := src.GetLoginCredentials(loginProfile)
			credentials := &model.LoginCredentials{
				ID:       &profile.ID,
				Type:     resolved.Type,
				Hostname: resolved.Hostname,
				Username: resolved.Username,
				Password: resolved.Password,
				Database: resolved.Database,
				Advanced: func() []*model.RecordInput {
					out := make([]*model.RecordInput, 0, len(resolved.Advanced))
					for _, rec := range resolved.Advanced {
						out = append(out, &model.RecordInput{Key: rec.Key, Value: rec.Value})
					}
					return out
				}(),
			}
			if profile.Database != nil && *profile.Database != "" {
				credentials.Database = *profile.Database
				resolved.Database = credentials.Database
			}

			identity := strings.TrimSpace(analytics.MetadataFromContext(ctx).DistinctID)
			hasIdentity := identity != "" && identity != "disabled"

			if hasIdentity {
				analytics.CaptureWithDistinctID(ctx, identity, "login_with_profile.attempt", map[string]any{
					"database_type":  loginProfile.Type,
					"profile_source": loginProfile.Source,
				})
			}

			if !src.MainEngine.Choose(engine.DatabaseType(loginProfile.Type)).IsAvailable(&engine.PluginConfig{
				Credentials: resolved,
			}) {
				log.LogFields(log.Fields{
					"profile_id": profile.ID,
					"type":       loginProfile.Type,
				}).Error("Database connection failed for login profile - credentials unauthorized")

				if hasIdentity {
					analytics.CaptureWithDistinctID(ctx, identity, "login_with_profile.denied", map[string]any{
						"database_type":  loginProfile.Type,
						"profile_source": loginProfile.Source,
					})
				}
				return nil, errors.New("unauthorized")
			}

			resp, err := auth.Login(ctx, credentials)
			if err != nil {
				if hasIdentity {
					analytics.CaptureError(ctx, "login_with_profile.execute", err, map[string]any{
						"database_type":  loginProfile.Type,
						"profile_source": loginProfile.Source,
					})
				}
				return nil, err
			}

			if hasIdentity {
				traits := map[string]any{
					"profile_source": loginProfile.Source,
					"saved_profile":  true,
				}
				if hashedHost := analytics.HashIdentifier(credentials.Hostname); hashedHost != "" {
					traits["hostname_hash"] = hashedHost
				}
				if hashedDatabase := analytics.HashIdentifier(credentials.Database); hashedDatabase != "" {
					traits["database_hash"] = hashedDatabase
				}

				analytics.IdentifyWithDistinctID(ctx, identity, traits)
				analytics.CaptureWithDistinctID(ctx, identity, "login_with_profile.success", map[string]any{
					"database_type":  loginProfile.Type,
					"profile_source": loginProfile.Source,
				})
			}

			return resp, nil
		}
	}
	log.LogFields(log.Fields{
		"profile_id": profile.ID,
	}).Error("Login profile not found or not authorized")
	return nil, errors.New("login profile does not exist or is not authorized")
}

// Logout is the resolver for the Logout field.
func (r *mutationResolver) Logout(ctx context.Context) (*model.StatusResponse, error) {
	creds := auth.GetCredentials(ctx)
	identity := strings.TrimSpace(analytics.MetadataFromContext(ctx).DistinctID)
	hasIdentity := identity != "" && identity != "disabled"
	hasProfile := false
	dbType := ""
	if creds != nil {
		hasProfile = creds.Id != nil && strings.TrimSpace(*creds.Id) != ""
		dbType = creds.Type
	}

	if hasIdentity {
		analytics.CaptureWithDistinctID(ctx, identity, "logout.attempt", map[string]any{
			"database_type":      dbType,
			"profile_id_present": hasProfile,
		})
	}

	resp, err := auth.Logout(ctx)
	if err != nil {
		if hasIdentity {
			analytics.CaptureError(ctx, "logout.execute", err, map[string]any{
				"database_type":      dbType,
				"profile_id_present": hasProfile,
			})
		}
		return nil, err
	}

	if hasIdentity {
		analytics.CaptureWithDistinctID(ctx, identity, "logout.success", map[string]any{
			"database_type":      dbType,
			"profile_id_present": hasProfile,
		})
	}

	return resp, nil
}

// UpdateSettings is the resolver for the UpdateSettings field.
func (r *mutationResolver) UpdateSettings(ctx context.Context, newSettings model.SettingsConfigInput) (*model.StatusResponse, error) {
	var fields []settings.ISettingsField

	if newSettings.MetricsEnabled != nil {
		metricsEnabled := common.StrPtrToBool(newSettings.MetricsEnabled)
		fields = append(fields, settings.MetricsEnabledField(metricsEnabled))

		analytics.TrackMutation(ctx, "UpdateSettings.metrics", map[string]any{
			"metrics_enabled": metricsEnabled,
		})
	}

	updated := settings.UpdateSettings(fields...)
	return &model.StatusResponse{
		Status: updated,
	}, nil
}

// AddStorageUnit is the resolver for the AddStorageUnit field.
func (r *mutationResolver) AddStorageUnit(ctx context.Context, schema string, storageUnit string, fields []*model.RecordInput) (*model.StatusResponse, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type
	var fieldsMap []engine.Record
	for _, field := range fields {
		extraFields := map[string]string{}
		for _, extraField := range field.Extra {
			extraFields[extraField.Key] = extraField.Value
		}
		fieldsMap = append(fieldsMap, engine.Record{
			Key:   field.Key,
			Value: field.Value,
			Extra: extraFields,
		})
	}
	status, err := plugin.AddStorageUnit(config, schema, storageUnit, fieldsMap)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "AddStorageUnit",
			"schema":        schema,
			"storage_unit":  storageUnit,
			"database_type": typeArg,
		}).WithError(err).Error("Database operation failed")
		analytics.CaptureError(ctx, "AddStorageUnit", err, map[string]any{
			"database_type": typeArg,
			"schema_hash":   analytics.HashIdentifier(schema),
			"storage_hash":  analytics.HashIdentifier(storageUnit),
		})
		return nil, err
	}

	analytics.TrackMutation(ctx, "AddStorageUnit", map[string]any{
		"database_type": typeArg,
		"schema_hash":   analytics.HashIdentifier(schema),
		"storage_hash":  analytics.HashIdentifier(storageUnit),
		"field_count":   len(fields),
	})

	return &model.StatusResponse{
		Status: status,
	}, nil
}

// UpdateStorageUnit is the resolver for the UpdateStorageUnit field.
func (r *mutationResolver) UpdateStorageUnit(ctx context.Context, schema string, storageUnit string, values []*model.RecordInput, updatedColumns []string) (*model.StatusResponse, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type

	if err := ValidateStorageUnit(plugin, config, schema, storageUnit); err != nil {
		return nil, err
	}

	valuesMap := map[string]string{}
	for _, value := range values {
		valuesMap[value.Key] = value.Value
	}
	status, err := plugin.UpdateStorageUnit(config, schema, storageUnit, valuesMap, updatedColumns)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":       "UpdateStorageUnit",
			"schema":          schema,
			"storage_unit":    storageUnit,
			"database_type":   typeArg,
			"updated_columns": len(updatedColumns),
		}).WithError(err).Error("Database operation failed")
		analytics.CaptureError(ctx, "UpdateStorageUnit", err, map[string]any{
			"database_type":   typeArg,
			"schema_hash":     analytics.HashIdentifier(schema),
			"storage_hash":    analytics.HashIdentifier(storageUnit),
			"updated_columns": len(updatedColumns),
			"values_supplied": len(values),
		})
		return nil, err
	}

	analytics.TrackMutation(ctx, "UpdateStorageUnit", map[string]any{
		"database_type":   typeArg,
		"schema_hash":     analytics.HashIdentifier(schema),
		"storage_hash":    analytics.HashIdentifier(storageUnit),
		"updated_columns": len(updatedColumns),
		"values_supplied": len(values),
	})

	return &model.StatusResponse{
		Status: status,
	}, nil
}

// AddRow is the resolver for the AddRow field.
func (r *mutationResolver) AddRow(ctx context.Context, schema string, storageUnit string, values []*model.RecordInput) (*model.StatusResponse, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type

	if err := ValidateStorageUnit(plugin, config, schema, storageUnit); err != nil {
		return nil, err
	}

	log.LogFields(log.Fields{
		"operation":     "AddRow-Resolver",
		"schema":        schema,
		"storage_unit":  storageUnit,
		"database_type": typeArg,
		"values_count":  len(values),
	}).Debug("AddRow resolver called")

	valuesRecords := []engine.Record{}
	for _, field := range values {
		extraFields := map[string]string{}
		for _, extraField := range field.Extra {
			extraFields[extraField.Key] = extraField.Value
		}
		valuesRecords = append(valuesRecords, engine.Record{
			Key:   field.Key,
			Value: field.Value,
			Extra: extraFields,
		})
	}

	status, err := plugin.AddRow(config, schema, storageUnit, valuesRecords)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "AddRow",
			"schema":        schema,
			"storage_unit":  storageUnit,
			"database_type": typeArg,
		}).WithError(err).Error("Database operation failed")
		analytics.CaptureError(ctx, "AddRow", err, map[string]any{
			"database_type": typeArg,
			"schema_hash":   analytics.HashIdentifier(schema),
			"storage_hash":  analytics.HashIdentifier(storageUnit),
			"value_count":   len(values),
		})
		return nil, err
	}

	analytics.TrackMutation(ctx, "AddRow", map[string]any{
		"database_type": typeArg,
		"schema_hash":   analytics.HashIdentifier(schema),
		"storage_hash":  analytics.HashIdentifier(storageUnit),
		"value_count":   len(values),
	})

	return &model.StatusResponse{
		Status: status,
	}, nil
}

// DeleteRow is the resolver for the DeleteRow field.
func (r *mutationResolver) DeleteRow(ctx context.Context, schema string, storageUnit string, values []*model.RecordInput) (*model.StatusResponse, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type

	if err := ValidateStorageUnit(plugin, config, schema, storageUnit); err != nil {
		return nil, err
	}

	valuesMap := map[string]string{}
	for _, value := range values {
		valuesMap[value.Key] = value.Value
	}
	status, err := plugin.DeleteRow(config, schema, storageUnit, valuesMap)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "DeleteRow",
			"schema":        schema,
			"storage_unit":  storageUnit,
			"database_type": typeArg,
		}).WithError(err).Error("Database operation failed")
		analytics.CaptureError(ctx, "DeleteRow", err, map[string]any{
			"database_type": typeArg,
			"schema_hash":   analytics.HashIdentifier(schema),
			"storage_hash":  analytics.HashIdentifier(storageUnit),
			"value_count":   len(values),
		})
		return nil, err
	}

	analytics.TrackMutation(ctx, "DeleteRow", map[string]any{
		"database_type": typeArg,
		"schema_hash":   analytics.HashIdentifier(schema),
		"storage_hash":  analytics.HashIdentifier(storageUnit),
		"value_count":   len(values),
	})

	return &model.StatusResponse{
		Status: status,
	}, nil
}

// GenerateMockData is the resolver for the GenerateMockData field.
func (r *mutationResolver) GenerateMockData(ctx context.Context, input model.MockDataGenerationInput) (*model.MockDataGenerationStatus, error) {
	log.Logger.WithField("schema", input.Schema).WithField("table", input.StorageUnit).WithField("rowCount", input.RowCount).WithField("overwrite", input.OverwriteExisting).Info("Starting mock data generation")

	maxRowLimit := env.GetMockDataGenerationMaxRowCount()
	if input.RowCount > maxRowLimit {
		log.Logger.WithField("requested", input.RowCount).WithField("max", maxRowLimit).Error("Row count exceeds maximum limit")
		return nil, fmt.Errorf("row count exceeds maximum limit of %d", maxRowLimit)
	}

	if !env.IsMockDataGenerationAllowed(input.StorageUnit) {
		log.Logger.WithField("table", input.StorageUnit).Error("Mock data generation not allowed for table")
		return nil, errors.New("mock data generation is not allowed for this table")
	}

	plugin, config := GetPluginForContext(ctx)

	fkRatio := 0
	if input.FkDensityRatio != nil {
		fkRatio = *input.FkDensityRatio
	}
	generator := src.NewMockDataGenerator(fkRatio)
	result, err := generator.Generate(plugin, config, input.Schema, input.StorageUnit, input.RowCount, input.OverwriteExisting)
	if err != nil {
		log.Logger.WithError(err).Error("Mock data generation failed")
		return nil, fmt.Errorf("mock data generation failed: %w", err)
	}

	var details []*model.MockDataTableDetail
	if len(result.Details) > 0 {
		details = make([]*model.MockDataTableDetail, len(result.Details))
		for i, d := range result.Details {
			details[i] = &model.MockDataTableDetail{
				Table:            d.Table,
				RowsGenerated:    d.RowsGenerated,
				UsedExistingData: d.UsedExistingData,
			}
		}
	}

	log.Logger.WithField("generatedRows", result.TotalGenerated).Info("Mock data generation completed successfully")
	return &model.MockDataGenerationStatus{
		AmountGenerated: result.TotalGenerated,
		Details:         details,
	}, nil
}

// ExecuteConfirmedSQL is the resolver for the ExecuteConfirmedSQL field.
func (r *mutationResolver) ExecuteConfirmedSQL(ctx context.Context, query string, operationType string) (*model.AIChatMessage, error) {
	// Get plugin and config from context
	plugin, config := GetPluginForContext(ctx)

	// Execute the SQL query
	result, execErr := plugin.RawExecute(config, query)

	message := &model.AIChatMessage{
		Type:                 operationType,
		Text:                 query,
		RequiresConfirmation: false,
	}

	if execErr != nil {
		message.Type = "error"
		message.Text = execErr.Error()
	} else {
		// Convert result
		var columns []*model.Column
		for _, column := range result.Columns {
			columns = append(columns, &model.Column{
				Type: column.Type,
				Name: column.Name,
			})
		}
		message.Result = &model.RowsResult{
			Columns: columns,
			Rows:    result.Rows,
		}
	}

	return message, nil
}

// AddAWSProvider is the resolver for the AddAWSProvider field.
func (r *mutationResolver) AddAWSProvider(ctx context.Context, input model.AWSProviderInput) (*model.AWSProvider, error) {
	if !env.IsAWSProviderEnabled {
		return nil, aws.ErrAWSProviderDisabled
	}

	id := settings.GenerateProviderID(input.Name, input.Region)

	authMethod := "default"
	if input.AuthMethod != nil && *input.AuthMethod != "" {
		authMethod = *input.AuthMethod
	}

	discoverRDS := true
	if input.DiscoverRds != nil {
		discoverRDS = *input.DiscoverRds
	}

	discoverElastiCache := true
	if input.DiscoverElastiCache != nil {
		discoverElastiCache = *input.DiscoverElastiCache
	}

	discoverDocumentDB := true
	if input.DiscoverDocumentDb != nil {
		discoverDocumentDB = *input.DiscoverDocumentDb
	}

	cfg := &settings.AWSProviderConfig{
		ID:                  id,
		Name:                input.Name,
		Region:              input.Region,
		AuthMethod:          authMethod,
		DiscoverRDS:         discoverRDS,
		DiscoverElastiCache: discoverElastiCache,
		DiscoverDocumentDB:  discoverDocumentDB,
	}

	if input.AccessKeyID != nil {
		cfg.AccessKeyID = *input.AccessKeyID
	}
	if input.SecretAccessKey != nil {
		cfg.SecretAccessKey = *input.SecretAccessKey
	}
	if input.SessionToken != nil {
		cfg.SessionToken = *input.SessionToken
	}
	if input.ProfileName != nil {
		cfg.ProfileName = *input.ProfileName
	}
	if input.DBUsername != nil {
		cfg.DBUsername = *input.DBUsername
	}

	state, err := settings.AddAWSProvider(cfg)
	if err != nil {
		return nil, err
	}

	return stateToAWSProvider(state), nil
}

// UpdateAWSProvider is the resolver for the UpdateAWSProvider field.
func (r *mutationResolver) UpdateAWSProvider(ctx context.Context, id string, input model.AWSProviderInput) (*model.AWSProvider, error) {
	if !env.IsAWSProviderEnabled {
		return nil, aws.ErrAWSProviderDisabled
	}

	existing, err := settings.GetAWSProvider(id)
	if err != nil {
		return nil, err
	}

	authMethod := existing.Config.AuthMethod
	if input.AuthMethod != nil && *input.AuthMethod != "" {
		authMethod = *input.AuthMethod
	}

	discoverRDS := existing.Config.DiscoverRDS
	if input.DiscoverRds != nil {
		discoverRDS = *input.DiscoverRds
	}

	discoverElastiCache := existing.Config.DiscoverElastiCache
	if input.DiscoverElastiCache != nil {
		discoverElastiCache = *input.DiscoverElastiCache
	}

	discoverDocumentDB := existing.Config.DiscoverDocumentDB
	if input.DiscoverDocumentDb != nil {
		discoverDocumentDB = *input.DiscoverDocumentDb
	}

	cfg := &settings.AWSProviderConfig{
		ID:                  id,
		Name:                input.Name,
		Region:              input.Region,
		AuthMethod:          authMethod,
		DiscoverRDS:         discoverRDS,
		DiscoverElastiCache: discoverElastiCache,
		DiscoverDocumentDB:  discoverDocumentDB,
	}

	// Clear credentials that don't apply to the new auth method to prevent stale data
	authMethodChanged := authMethod != existing.Config.AuthMethod
	switch authMethod {
	case "static":
		// Static auth uses AccessKeyID/SecretAccessKey
		if input.AccessKeyID != nil {
			cfg.AccessKeyID = *input.AccessKeyID
		} else {
			cfg.AccessKeyID = existing.Config.AccessKeyID
		}
		if input.SecretAccessKey != nil {
			cfg.SecretAccessKey = *input.SecretAccessKey
		} else {
			cfg.SecretAccessKey = existing.Config.SecretAccessKey
		}
		if input.SessionToken != nil {
			cfg.SessionToken = *input.SessionToken
		} else {
			cfg.SessionToken = existing.Config.SessionToken
		}
		// Clear profile if switching to static
		if authMethodChanged {
			cfg.ProfileName = ""
		} else if input.ProfileName != nil {
			cfg.ProfileName = *input.ProfileName
		}
	case "profile":
		// Profile auth uses ProfileName - clear static credentials
		if input.ProfileName != nil {
			cfg.ProfileName = *input.ProfileName
		} else {
			cfg.ProfileName = existing.Config.ProfileName
		}
		if authMethodChanged {
			// Clear static credentials when switching to profile
			cfg.AccessKeyID = ""
			cfg.SecretAccessKey = ""
			cfg.SessionToken = ""
		}
	default:
		// "default", "env", "iam" don't need stored credentials
		if authMethodChanged {
			cfg.AccessKeyID = ""
			cfg.SecretAccessKey = ""
			cfg.SessionToken = ""
			cfg.ProfileName = ""
		}
	}

	// Handle DBUsername (used for IAM auth)
	if input.DBUsername != nil {
		cfg.DBUsername = *input.DBUsername
	} else {
		cfg.DBUsername = existing.Config.DBUsername
	}

	state, err := settings.UpdateAWSProvider(id, cfg)
	if err != nil {
		return nil, err
	}

	return stateToAWSProvider(state), nil
}

// RemoveCloudProvider is the resolver for the RemoveCloudProvider field.
func (r *mutationResolver) RemoveCloudProvider(ctx context.Context, id string) (*model.StatusResponse, error) {
	if !env.IsAWSProviderEnabled {
		return &model.StatusResponse{Status: false}, aws.ErrAWSProviderDisabled
	}

	// Router pattern: when adding GCP, dispatch based on settings.GetProviderType(id).
	// See .claude/docs/cloud-providers.md for full example.
	err := settings.RemoveAWSProvider(id)
	if err != nil {
		return &model.StatusResponse{Status: false}, err
	}
	return &model.StatusResponse{Status: true}, nil
}

// TestCloudProvider is the resolver for the TestCloudProvider field.
func (r *mutationResolver) TestCloudProvider(ctx context.Context, id string) (model.CloudProviderStatus, error) {
	if !env.IsAWSProviderEnabled {
		return model.CloudProviderStatusError, aws.ErrAWSProviderDisabled
	}

	status, err := settings.TestAWSProvider(id)
	if err != nil {
		return model.CloudProviderStatusError, err
	}
	return mapCloudProviderStatus(status), nil
}

// RefreshCloudProvider is the resolver for the RefreshCloudProvider field.
func (r *mutationResolver) RefreshCloudProvider(ctx context.Context, id string) (*model.AWSProvider, error) {
	if !env.IsAWSProviderEnabled {
		return nil, aws.ErrAWSProviderDisabled
	}

	state, err := settings.RefreshAWSProvider(id)
	if err != nil {
		return nil, err
	}
	return stateToAWSProvider(state), nil
}

// Version is the resolver for the Version field.
func (r *queryResolver) Version(ctx context.Context) (string, error) {
	if env.ApplicationVersion != "" {
		return env.ApplicationVersion, nil
	}
	// Default fallback for development
	return "development", nil
}

// Health is the resolver for the Health field.
func (r *queryResolver) Health(ctx context.Context) (*model.HealthStatus, error) {
	status := &model.HealthStatus{
		Server:   "healthy",
		Database: "unavailable",
	}

	// Check if user is authenticated and has credentials
	credentials := auth.GetCredentials(ctx)
	if credentials != nil && credentials.Type != "" {
		config := engine.NewPluginConfig(credentials)
		plugin := src.MainEngine.Choose(engine.DatabaseType(config.Credentials.Type))

		if plugin != nil {
			// Create a context with 2 second timeout
			healthCtx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
			defer cancel()

			done := make(chan bool, 1)

			go func() {
				defer func() {
					if r := recover(); r != nil {
						// Panic in database check - mark as error
					}
					done <- true
				}()

				_, err := plugin.GetDatabases(config)
				if err == nil {
					status.Database = "healthy"
				} else {
					status.Database = "error"
				}
			}()

			select {
			case <-done:
				// Health check completed
			case <-healthCtx.Done():
				// Timeout - database is not responding
				status.Database = "error"
			}
		}
	}

	return status, nil
}

// Profiles is the resolver for the Profiles field.
func (r *queryResolver) Profiles(ctx context.Context) ([]*model.LoginProfile, error) {
	var profiles []*model.LoginProfile
	for i, profile := range src.GetLoginProfiles() {
		profileName := src.GetLoginProfileId(i, profile)

		// Check if SSL is configured (mode is set and not "disabled")
		sslConfigured := false
		if mode, ok := profile.Config[ssl.KeySSLMode]; ok && mode != "" && mode != string(ssl.SSLModeDisabled) {
			sslConfigured = true
		}

		loginProfile := &model.LoginProfile{
			ID:                   profileName,
			Type:                 model.DatabaseType(profile.Type),
			Hostname:             &profile.Hostname,
			Database:             &profile.Database,
			IsEnvironmentDefined: true,
			Source:               profile.Source,
			SSLConfigured:        sslConfigured,
		}
		if len(profile.Alias) > 0 {
			loginProfile.Alias = &profile.Alias
		}
		if len(profile.CustomId) > 0 {
			loginProfile.ID = profile.CustomId
		}
		profiles = append(profiles, loginProfile)
	}
	return profiles, nil
}

// Database is the resolver for the Database field.
// This resolver is used in two scenarios:
// 1. Login page: to get available databases (e.g., SQLite files) before authentication
// 2. Sidebar: to get switchable databases when already logged in
//
// For the sidebar case, we use session credentials. For login page, we fall back
// to a minimal config (works for SQLite which scans filesystem, not for MySQL which needs connection).
func (r *queryResolver) Database(ctx context.Context, typeArg string) ([]string, error) {
	plugin := src.MainEngine.Choose(engine.DatabaseType(typeArg))
	if plugin == nil {
		return nil, fmt.Errorf("unsupported database type: %s", typeArg)
	}

	var config *engine.PluginConfig

	// Try to get credentials from session (for sidebar when logged in)
	credentials := auth.GetCredentials(ctx)
	if credentials != nil && credentials.Type == typeArg {
		config = engine.NewPluginConfig(credentials)
	} else {
		// No session or type mismatch - use minimal config. works for sqlite
		config = &engine.PluginConfig{
			Credentials: &engine.Credentials{
				Type: typeArg,
			},
		}
	}

	databases, err := plugin.GetDatabases(config)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "GetDatabases",
			"database_type": typeArg,
		}).WithError(err).Error("Database operation failed")
		return nil, err
	}
	return databases, nil
}

// Schema is the resolver for the Schema field.
func (r *queryResolver) Schema(ctx context.Context) ([]string, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type
	schemas, err := plugin.GetAllSchemas(config)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "GetAllSchemas",
			"database_type": typeArg,
		}).WithError(err).Error("Database operation failed")
		return nil, err
	}
	return schemas, nil
}

// StorageUnit is the resolver for the StorageUnit field.
func (r *queryResolver) StorageUnit(ctx context.Context, schema string) ([]*model.StorageUnit, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type
	units, err := plugin.GetStorageUnits(config, schema)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "GetStorageUnits",
			"schema":        schema,
			"database_type": typeArg,
		}).WithError(err).Error("Database operation failed")
		return nil, err
	}
	var storageUnits []*model.StorageUnit
	for _, unit := range units {
		storageUnit := engine.GetStorageUnitModel(unit)
		storageUnit.IsMockDataGenerationAllowed = env.IsMockDataGenerationAllowed(unit.Name)
		storageUnits = append(storageUnits, storageUnit)
	}
	return storageUnits, nil
}

// Row is the resolver for the Row field.
func (r *queryResolver) Row(ctx context.Context, schema string, storageUnit string, where *model.WhereCondition, sort []*model.SortCondition, pageSize int, pageOffset int) (*model.RowsResult, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type

	if err := ValidateStorageUnit(plugin, config, schema, storageUnit); err != nil {
		return nil, err
	}

	// Run GetRows, GetColumnConstraints, and GetForeignKeyRelationships in parallel
	var rowsResult *engine.GetRowsResult
	var constraints map[string]map[string]any
	var foreignKeys map[string]*engine.ForeignKeyRelationship

	g, _ := errgroup.WithContext(ctx)

	g.Go(func() error {
		var err error
		rowsResult, err = plugin.GetRows(config, schema, storageUnit, where, sort, pageSize, pageOffset)
		if err != nil {
			log.LogFields(log.Fields{
				"operation":     "GetRows",
				"schema":        schema,
				"storage_unit":  storageUnit,
				"database_type": typeArg,
				"page_size":     pageSize,
				"page_offset":   pageOffset,
			}).WithError(err).Error("Database operation failed")
			return err
		}
		return nil
	})

	g.Go(func() error {
		var err error
		constraints, err = plugin.GetColumnConstraints(config, schema, storageUnit)
		if err != nil {
			log.LogFields(log.Fields{
				"operation":    "GetColumnConstraints",
				"schema":       schema,
				"storage_unit": storageUnit,
				"error":        err.Error(),
			}).Warn("Failed to get column constraints, primary key detection unavailable")
			constraints = make(map[string]map[string]any)
		}
		return nil // Non-critical, don't fail the request
	})

	g.Go(func() error {
		var err error
		foreignKeys, err = plugin.GetForeignKeyRelationships(config, schema, storageUnit)
		if err != nil {
			log.LogFields(log.Fields{
				"operation":    "GetForeignKeyRelationships",
				"schema":       schema,
				"storage_unit": storageUnit,
				"error":        err.Error(),
			}).Warn("Failed to get foreign key relationships")
			foreignKeys = make(map[string]*engine.ForeignKeyRelationship)
		}
		return nil // Non-critical, don't fail the request
	})

	if err := g.Wait(); err != nil {
		return nil, err
	}

	var columns []*model.Column
	for _, column := range rowsResult.Columns {
		isPrimary := false
		if colConstraints, ok := constraints[column.Name]; ok {
			if primary, exists := colConstraints["primary"]; exists {
				if primaryBool, isBool := primary.(bool); isBool {
					isPrimary = primaryBool
				}
			}
		}

		// Check if this column has a foreign key constraint
		var referencedTable *string
		var referencedColumn *string
		isForeignKey := false
		if fk, exists := foreignKeys[column.Name]; exists {
			isForeignKey = true
			referencedTable = &fk.ReferencedTable
			referencedColumn = &fk.ReferencedColumn
		}

		columns = append(columns, &model.Column{
			Type:             column.Type,
			Name:             column.Name,
			IsPrimary:        isPrimary,
			IsForeignKey:     isForeignKey,
			ReferencedTable:  referencedTable,
			ReferencedColumn: referencedColumn,
			Length:           column.Length,
			Precision:        column.Precision,
			Scale:            column.Scale,
		})
	}
	return &model.RowsResult{
		Columns:       columns,
		Rows:          rowsResult.Rows,
		DisableUpdate: rowsResult.DisableUpdate,
		TotalCount:    int(rowsResult.TotalCount),
	}, nil
}

// Columns is the resolver for the Columns field.
func (r *queryResolver) Columns(ctx context.Context, schema string, storageUnit string) ([]*model.Column, error) {
	plugin, config := GetPluginForContext(ctx)
	columns, err := FetchColumnsForStorageUnit(plugin, config, schema, storageUnit)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "Columns",
			"schema":        schema,
			"storage_unit":  storageUnit,
			"database_type": config.Credentials.Type,
			"error":         err.Error(),
		}).Error("Failed to fetch columns")
		return nil, err
	}
	return columns, nil
}

// ColumnsBatch is the resolver for the ColumnsBatch field.
func (r *queryResolver) ColumnsBatch(ctx context.Context, schema string, storageUnits []string) ([]*model.StorageUnitColumns, error) {
	plugin, config := GetPluginForContext(ctx)

	results := make([]*model.StorageUnitColumns, len(storageUnits))
	g, _ := errgroup.WithContext(ctx)

	for i, storageUnit := range storageUnits {
		i, storageUnit := i, storageUnit
		g.Go(func() error {
			columns, err := FetchColumnsForStorageUnit(plugin, config, schema, storageUnit)
			if err != nil {
				log.LogFields(log.Fields{
					"operation":     "ColumnsBatch",
					"schema":        schema,
					"storage_unit":  storageUnit,
					"database_type": config.Credentials.Type,
					"error":         err.Error(),
				}).Error("Failed to fetch columns")
				// Don't fail the entire batch - just skip this table
				results[i] = nil
				return nil
			}
			results[i] = &model.StorageUnitColumns{
				StorageUnit: storageUnit,
				Columns:     columns,
			}
			return nil
		})
	}

	if err := g.Wait(); err != nil {
		return nil, err
	}

	// Filter out nil results (tables that failed to load)
	successfulResults := make([]*model.StorageUnitColumns, 0, len(results))
	for _, result := range results {
		if result != nil {
			successfulResults = append(successfulResults, result)
		}
	}

	return successfulResults, nil
}

// RawExecute is the resolver for the RawExecute field.
func (r *queryResolver) RawExecute(ctx context.Context, query string) (*model.RowsResult, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type
	rowsResult, err := plugin.RawExecute(config, query)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "RawExecute",
			"database_type": typeArg,
			"query":         query,
		}).WithError(err).Error("Database operation failed")
		return nil, err
	}
	var columns []*model.Column
	for _, column := range rowsResult.Columns {
		columns = append(columns, &model.Column{
			Type:         column.Type,
			Name:         column.Name,
			IsPrimary:    column.IsPrimary,
			IsForeignKey: column.IsForeignKey,
		})
	}
	return &model.RowsResult{
		Columns: columns,
		Rows:    rowsResult.Rows,
	}, nil
}

// Graph is the resolver for the Graph field.
func (r *queryResolver) Graph(ctx context.Context, schema string) ([]*model.GraphUnit, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type
	graphUnits, err := plugin.GetGraph(config, schema)
	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "GetGraph",
			"schema":        schema,
			"database_type": typeArg,
		}).WithError(err).Error("Database operation failed")
		return nil, err
	}
	var graphUnitsModel []*model.GraphUnit
	for _, graphUnit := range graphUnits {
		var relations []*model.GraphUnitRelationship
		for _, relation := range graphUnit.Relations {
			relations = append(relations, &model.GraphUnitRelationship{
				Name:         relation.Name,
				Relationship: model.GraphUnitRelationshipType(relation.RelationshipType),
				SourceColumn: relation.SourceColumn,
				TargetColumn: relation.TargetColumn,
			})
		}
		graphUnitsModel = append(graphUnitsModel, &model.GraphUnit{
			Unit:      engine.GetStorageUnitModel(graphUnit.Unit),
			Relations: relations,
		})
	}
	return graphUnitsModel, nil
}

// AIProviders is the resolver for the AIProviders field.
func (r *queryResolver) AIProviders(ctx context.Context) ([]*model.AIProvider, error) {
	chatProviders := env.GetConfiguredChatProviders()
	var aiProviders []*model.AIProvider
	for _, provider := range chatProviders {
		aiProviders = append(aiProviders, &model.AIProvider{
			Type:                 provider.Type,
			Name:                 provider.Name,
			ProviderID:           provider.ProviderId,
			IsEnvironmentDefined: true,
			IsGeneric:            provider.IsGeneric,
		})
	}
	return aiProviders, nil
}

// AIModel is the resolver for the AIModel field.
func (r *queryResolver) AIModel(ctx context.Context, providerID *string, modelType string, token *string) ([]string, error) {
	config := engine.NewPluginConfig(auth.GetCredentials(ctx))

	// Initialize ExternalModel to prevent nil pointer dereference
	config.ExternalModel = &engine.ExternalModel{
		Type: modelType,
	}

	if providerID != nil {
		// Try to find provider in environment-defined providers first
		chatProviders := env.GetConfiguredChatProviders()
		found := false
		for _, provider := range chatProviders {
			if provider.ProviderId == *providerID {
				config.ExternalModel.Token = provider.APIKey
				found = true

				// For generic providers, return models from config instead of querying registry
				if provider.IsGeneric {
					for _, genericProvider := range env.GenericProviders {
						if genericProvider.ProviderId == *providerID {
							return genericProvider.Models, nil
						}
					}
				}
				break
			}
		}
		// If provider not found in environment but token is provided, use the token
		// This handles user-added providers that aren't in environment
		if !found && token != nil {
			config.ExternalModel.Token = *token
		}
	} else if token != nil {
		config.ExternalModel.Token = *token
	}
	models, err := llm.Instance(config).GetSupportedModels()
	if err != nil {
		log.LogFields(log.Fields{
			"operation":   "GetSupportedModels",
			"model_type":  modelType,
			"provider_id": providerID,
			"error":       err.Error(),
		}).Error("AI operation failed")
		return nil, err
	}
	return models, nil
}

// AIChat is the resolver for the AIChat field.
func (r *queryResolver) AIChat(ctx context.Context, providerID *string, modelType string, token *string, schema string, input model.ChatInput) ([]*model.AIChatMessage, error) {
	plugin, config := GetPluginForContext(ctx)
	typeArg := config.Credentials.Type
	if providerID != nil {
		// Try to find provider in environment-defined providers first
		chatProviders := env.GetConfiguredChatProviders()
		found := false
		for _, provider := range chatProviders {
			if provider.ProviderId == *providerID {
				config.ExternalModel = &engine.ExternalModel{
					Type:     modelType,
					Token:    provider.APIKey,
					Model:    input.Model,
					Endpoint: provider.Endpoint,
				}
				found = true
				break
			}
		}
		// If provider not found in environment but token is provided, use the token
		// This handles user-added providers that aren't in environment
		if !found {
			config.ExternalModel = &engine.ExternalModel{
				Type:  modelType,
				Model: input.Model,
			}
			if token != nil {
				config.ExternalModel.Token = *token
			}
		}
	} else {
		config.ExternalModel = &engine.ExternalModel{
			Type:  modelType,
			Model: input.Model,
		}
		if token != nil {
			config.ExternalModel.Token = *token
		}
	}
	messages, err := plugin.Chat(config, schema, input.PreviousConversation, input.Query)

	if err != nil {
		log.LogFields(log.Fields{
			"operation":     "Chat",
			"schema":        schema,
			"database_type": typeArg,
			"model":         input.Model,
			"model_type":    modelType,
			"provider_id":   providerID,
			"query":         input.Query,
			"error":         err.Error(),
		}).Error("AI chat operation failed")
		return nil, err
	}

	var chatResponse []*model.AIChatMessage

	for _, message := range messages {
		var result *model.RowsResult
		if strings.HasPrefix(message.Type, "sql") {
			var columns []*model.Column
			for _, column := range message.Result.Columns {
				columns = append(columns, &model.Column{
					Type: column.Type,
					Name: column.Name,
				})
			}
			result = &model.RowsResult{
				Columns: columns,
				Rows:    message.Result.Rows,
			}
		}
		chatResponse = append(chatResponse, &model.AIChatMessage{
			Type:                 message.Type,
			Result:               result,
			Text:                 message.Text,
			RequiresConfirmation: message.RequiresConfirmation,
		})
	}

	return chatResponse, nil
}

// SettingsConfig is the resolver for the SettingsConfig field.
func (r *queryResolver) SettingsConfig(ctx context.Context) (*model.SettingsConfig, error) {
	currentSettings := settings.Get()
	return &model.SettingsConfig{
		MetricsEnabled:        &currentSettings.MetricsEnabled,
		CloudProvidersEnabled: env.IsAWSProviderEnabled,
		DisableCredentialForm: env.DisableCredentialForm,
	}, nil
}

// MockDataMaxRowCount is the resolver for the MockDataMaxRowCount field.
func (r *queryResolver) MockDataMaxRowCount(ctx context.Context) (int, error) {
	return env.GetMockDataGenerationMaxRowCount(), nil
}

// AnalyzeMockDataDependencies analyzes FK dependencies for mock data generation.
func (r *queryResolver) AnalyzeMockDataDependencies(ctx context.Context, schema string, storageUnit string, rowCount int, fkDensityRatio *int) (*model.MockDataDependencyAnalysis, error) {
	maxRowLimit := env.GetMockDataGenerationMaxRowCount()
	if rowCount > maxRowLimit {
		errMsg := fmt.Sprintf("row count exceeds maximum limit of %d", maxRowLimit)
		return &model.MockDataDependencyAnalysis{
			Error: &errMsg,
		}, nil
	}

	if !env.IsMockDataGenerationAllowed(storageUnit) {
		errMsg := "mock data generation is not allowed for this table"
		return &model.MockDataDependencyAnalysis{
			Error: &errMsg,
		}, nil
	}

	plugin, config := GetPluginForContext(ctx)
	if plugin == nil {
		return nil, errors.New("no database connection")
	}

	fkRatio := 0
	if fkDensityRatio != nil {
		fkRatio = *fkDensityRatio
	}
	generator := src.NewMockDataGenerator(fkRatio)
	analysis, err := generator.AnalyzeDependencies(plugin, config, schema, storageUnit, rowCount)
	if err != nil {
		errMsg := err.Error()
		return &model.MockDataDependencyAnalysis{
			Error: &errMsg,
		}, nil
	}

	tables := make([]*model.MockDataTableInfo, 0, len(analysis.Tables))
	for _, t := range analysis.Tables {
		tables = append(tables, &model.MockDataTableInfo{
			Table:            t.Table,
			RowsToGenerate:   t.RowCount,
			IsBlocked:        t.IsBlocked,
			UsesExistingData: t.UsesExistingData,
		})
	}

	var errorPtr *string
	if analysis.Error != "" {
		errorPtr = &analysis.Error
	}

	return &model.MockDataDependencyAnalysis{
		GenerationOrder: analysis.GenerationOrder,
		Tables:          tables,
		TotalRows:       analysis.TotalRows,
		Warnings:        analysis.Warnings,
		Error:           errorPtr,
	}, nil
}

// DatabaseMetadata is the resolver for the DatabaseMetadata field.
func (r *queryResolver) DatabaseMetadata(ctx context.Context) (*model.DatabaseMetadata, error) {
	plugin, _ := GetPluginForContext(ctx)
	if plugin == nil {
		return nil, nil
	}
	metadata := plugin.GetDatabaseMetadata()

	// Return nil if plugin doesn't implement metadata (default GormPlugin behavior)
	if metadata == nil {
		return nil, nil
	}

	// Convert engine.TypeDefinition to model.TypeDefinition
	typeDefinitions := make([]*model.TypeDefinition, 0, len(metadata.TypeDefinitions))
	for _, td := range metadata.TypeDefinitions {
		typeDefinitions = append(typeDefinitions, &model.TypeDefinition{
			ID:               td.ID,
			Label:            td.Label,
			HasLength:        td.HasLength,
			HasPrecision:     td.HasPrecision,
			DefaultLength:    td.DefaultLength,
			DefaultPrecision: td.DefaultPrecision,
			Category:         model.TypeCategory(td.Category),
		})
	}

	// Convert map[string]string to []*model.Record
	aliasMap := make([]*model.Record, 0, len(metadata.AliasMap))
	for key, value := range metadata.AliasMap {
		aliasMap = append(aliasMap, &model.Record{
			Key:   key,
			Value: value,
		})
	}

	return &model.DatabaseMetadata{
		DatabaseType:    string(metadata.DatabaseType),
		TypeDefinitions: typeDefinitions,
		Operators:       metadata.Operators,
		AliasMap:        aliasMap,
	}, nil
}

// SSLStatus is the resolver for the SSLStatus field.
func (r *queryResolver) SSLStatus(ctx context.Context) (*model.SSLStatus, error) {
	plugin, config := GetPluginForContext(ctx)
	if plugin == nil {
		log.Logger.Debug("[SSL] SSLStatus resolver: no plugin context")
		return nil, nil
	}

	log.Logger.Debugf("[SSL] SSLStatus resolver: querying SSL status for %s", config.Credentials.Type)
	status, err := plugin.GetSSLStatus(config)
	if err != nil {
		log.Logger.Warnf("[SSL] SSLStatus resolver: error getting SSL status: %v", err)
		return nil, err
	}

	// Return nil if SSL status is not applicable (e.g., SQLite)
	if status == nil {
		log.Logger.Debugf("[SSL] SSLStatus resolver: SSL not applicable for %s", config.Credentials.Type)
		return nil, nil
	}

	log.Logger.Infof("[SSL] SSLStatus resolver: %s connection SSL enabled=%t, mode=%s",
		config.Credentials.Type, status.IsEnabled, status.Mode)

	return &model.SSLStatus{
		IsEnabled: status.IsEnabled,
		Mode:      status.Mode,
	}, nil
}

// CloudProviders is the resolver for the CloudProviders field.
func (r *queryResolver) CloudProviders(ctx context.Context) ([]*model.AWSProvider, error) {
	if !env.IsAWSProviderEnabled {
		return []*model.AWSProvider{}, nil
	}

	// Router pattern: when adding GCP, append settings.GetGCPProviders() results here.
	// See .claude/docs/cloud-providers.md for full example.
	states := settings.GetAWSProviders()
	result := make([]*model.AWSProvider, 0, len(states))
	for _, state := range states {
		result = append(result, stateToAWSProvider(state))
	}
	return result, nil
}

// CloudProvider is the resolver for the CloudProvider field.
func (r *queryResolver) CloudProvider(ctx context.Context, id string) (*model.AWSProvider, error) {
	if !env.IsAWSProviderEnabled {
		return nil, nil
	}

	state, err := settings.GetAWSProvider(id)
	if err != nil {
		return nil, err
	}
	return stateToAWSProvider(state), nil
}

// DiscoveredConnections is the resolver for the DiscoveredConnections field.
func (r *queryResolver) DiscoveredConnections(ctx context.Context) ([]*model.DiscoveredConnection, error) {
	if !env.IsAWSProviderEnabled {
		return []*model.DiscoveredConnection{}, nil
	}

	registry := providers.GetDefaultRegistry()
	conns, err := registry.DiscoverAll(ctx)

	result := make([]*model.DiscoveredConnection, 0, len(conns))
	for _, conn := range conns {
		result = append(result, discoveredConnectionToModel(&conn))
	}

	// Return partial results with error so UI can show a warning
	if err != nil {
		log.Logger.Warn("Error discovering connections: ", err)
		return result, err
	}
	return result, nil
}

// ProviderConnections is the resolver for the ProviderConnections field.
func (r *queryResolver) ProviderConnections(ctx context.Context, providerID string) ([]*model.DiscoveredConnection, error) {
	if !env.IsAWSProviderEnabled {
		return []*model.DiscoveredConnection{}, nil
	}

	registry := providers.GetDefaultRegistry()
	conns, err := registry.FilterByProvider(ctx, providerID)
	if err != nil {
		return nil, err
	}

	result := make([]*model.DiscoveredConnection, 0, len(conns))
	for _, conn := range conns {
		result = append(result, discoveredConnectionToModel(&conn))
	}
	return result, nil
}

// LocalAWSProfiles is the resolver for the LocalAWSProfiles field.
func (r *queryResolver) LocalAWSProfiles(ctx context.Context) ([]*model.LocalAWSProfile, error) {
	if !env.IsAWSProviderEnabled {
		return []*model.LocalAWSProfile{}, nil
	}

	localProfiles, err := aws.DiscoverLocalProfiles()
	if err != nil {
		return nil, err
	}

	result := make([]*model.LocalAWSProfile, len(localProfiles))
	for i, profile := range localProfiles {
		var region *string
		if profile.Region != "" {
			region = &profile.Region
		}
		result[i] = &model.LocalAWSProfile{
			Name:      profile.Name,
			Region:    region,
			Source:    profile.Source,
			IsDefault: profile.IsDefault,
		}
	}
	return result, nil
}

// AWSRegions is the resolver for the AWSRegions field.
func (r *queryResolver) AWSRegions(ctx context.Context) ([]*model.AWSRegion, error) {
	if !env.IsAWSProviderEnabled {
		return []*model.AWSRegion{}, nil
	}

	regions := aws.GetRegions()
	result := make([]*model.AWSRegion, len(regions))
	for i, region := range regions {
		result[i] = &model.AWSRegion{
			ID:          region.ID,
			Description: region.Description,
		}
	}
	return result, nil
}

// Mutation returns MutationResolver implementation.
func (r *Resolver) Mutation() MutationResolver { return &mutationResolver{r} }

// Query returns QueryResolver implementation.
func (r *Resolver) Query() QueryResolver { return &queryResolver{r} }

type mutationResolver struct{ *Resolver }
type queryResolver struct{ *Resolver }
